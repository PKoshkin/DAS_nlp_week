{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/probabll/dgm4nlp/blob/master/notebooks/sst/SST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Udt3kHMdWvYe"
   },
   "source": [
    "We will need to import some helper code, so we need to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8eXUCRiWvYi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYhItDYMZi6a"
   },
   "source": [
    "# Colab\n",
    "\n",
    "We will need to download some data for this notebook, so if you are using [colab](https://colab.research.google.com), set the `using_colab` flag below to `True` in order to clone our [github repo](https://github.com/probabll/dgm4nlp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_shCMftIx1rW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                     kolka_working_SST-Copy1.ipynb\r\n",
      "SST.ipynb                     kolka_working_SST.ipynb\r\n",
      "__init__.py                   my_first_SST.ipynb\r\n",
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m                   \u001b[1m\u001b[36mnn\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m                          \u001b[31mplotting.py\u001b[m\u001b[m\r\n",
      "evaluate.py                   sstutil.py\r\n",
      "\u001b[1m\u001b[36mimg\u001b[m\u001b[m                           util.py\r\n"
     ]
    }
   ],
   "source": [
    "using_colab = not True\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-fFME2OW22i"
   },
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "  !rm -fr dgm4nlp sst\n",
    "  !git clone https://github.com/probabll/dgm4nlp.git\n",
    "  !cp -R dgm4nlp/notebooks/sst ./  \n",
    "  !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_7NCZlZacNu"
   },
   "source": [
    "Now we can start our lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9mH-rUhWvYq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# CPU should be fine for this lab\n",
    "device = torch.device('cpu')  \n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okMoxTJ9bWjc"
   },
   "source": [
    "# Sentiment Classification \n",
    "\n",
    "\n",
    "We are going to augment a sentiment classifier with a layer of discrete latent variables which will help us improve the model's interpretability. But first, let's quickly review the baseline task.\n",
    "\n",
    "\n",
    "In sentiment classification, we have some text input $x = \\langle x_1, \\ldots, x_n \\rangle$, e.g. a sentence or short paragraph, which expresses a certain sentiment $y$, i.e. one of $K$ classes, towards a subject (e.g. a film or a product). \n",
    "\n",
    "\n",
    "\n",
    "We can learn a sentiment classifier by learning a categorical distribution over classes for a given input:\n",
    "\n",
    "\\begin{align}\n",
    "Y|x &\\sim \\text{Cat}(f(x; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where the Categorical pmf is $\\text{Cat}(y|\\pi) = \\pi_y$.\n",
    "\n",
    "A categorical distribution over $K$ classes is parameterised by a $K$-dimensional probability vector, here we use a neural network $f$ to map from the input to this probability vector. Technically we say *a neural network parameterise our model*, that is, it computes the parameters of our categorical observation model. The figure below is a graphical depiction of the model: circled nodes are random variables (a shaded node is an observed variable), uncircled nodes are deterministic, a plate indicates multiple draws.\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/classifier.png\"  height=\"100\">\n",
    "\n",
    "The neural network (NN) $f(\\cdot; \\theta)$ has parameters of its own, i.e. the weights of the various architecture blocks used, which we denoted generically by $\\theta$.\n",
    "\n",
    "Suppose we have a dataset $\\mathcal D = \\{(x^{(1)}, y^{(1)}), \\ldots, (x^{(N)}, y^{(N)})\\}$ containing $N$ i.i.d. observations. Then we can use the log-likelihood function \n",
    "\\begin{align}\n",
    "\\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{N} \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\\n",
    "&= \\sum_{k=1}^{N} \\log \\text{Cat}(y^{(k)}|f(x^{(k)}; \\theta))\n",
    "\\end{align}\n",
    " to estimate $\\theta$ by maximisation:\n",
    " \\begin{align}\n",
    " \\theta^\\star = \\arg\\max_{\\theta \\in \\Theta} \\mathcal L(\\theta|\\mathcal D) ~ .\n",
    " \\end{align}\n",
    " \n",
    "\n",
    "We can use stochastic gradient-ascent to find a local optimum of $\\mathcal L(\\theta|\\mathcal D)$, which only requires a gradient estimate:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{|\\mathcal D|} \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\ \n",
    "&= \\sum_{k=1}^{|\\mathcal D|} \\frac{1}{N} N \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta)  \\\\\n",
    "&= \\mathbb E_{\\mathcal U(1/N)} \\left[ N \\nabla_\\theta  \\log P(y^{(K)}|x^{(K)}, \\theta) \\right]  \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{N}{M} \\sum_{m=1}^M \\nabla_\\theta  \\log P(y^{(k_m)}|x^{(k_m)}, \\theta) \\\\\n",
    "&\\text{where }K_m \\sim \\mathcal U(1/N)\n",
    "\\end{align}\n",
    "\n",
    "This is a Monte Carlo (MC) estimate of the gradient computed on $M$ data points selected uniformly at random from $\\mathcal D$.\n",
    "\n",
    "For as long as $f$ remains differentiable wrt to its inputs and parameters, we can rely on automatic differentiation to obtain gradient estimates.\n",
    "\n",
    "In what follows we show how to design $f$ and how to extend this basic model to a latent-variable model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LUjyO-39zan"
   },
   "source": [
    "## Data\n",
    "\n",
    "We provide you some code to load the data (see `sst.sstutil.examplereader`). Play with the snippet below and inspect a few training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4z8Bt5no9z6w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Examples\n",
      "First dev example: Example(tokens=['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "from sst.sstutil import examplereader, Vocabulary, load_glove    \n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader('../sst/data/sst/train.txt'))\n",
    "dev_data = list(examplereader('../sst/data/sst/dev.txt'))\n",
    "test_data = list(examplereader('../sst/data/sst/test.txt'))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Examples')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lB2lEsNuWvYx"
   },
   "source": [
    "## Architecture\n",
    "\n",
    "\n",
    "The function $f$ conditions on a high-dimensional input (i.e. text), so we need to convert it to continuous real vectors. This is the job an *encoder*. \n",
    "\n",
    "**Embedding Layer**\n",
    "\n",
    "The first step is to convert the words in $x$ to vectors, which in this lab we will do with a pre-trained embedding layer (we will use GloVe).\n",
    "\n",
    "We will denote the embedding of the $i$th word of the input by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf x_i = \\text{glove}(x_i)\n",
    "\\end{equation}\n",
    "\n",
    "**Encoder Layer**\n",
    "\n",
    "In this lab, an encoder takes a sequence of input vectors $\\mathbf x_1^n$, each $I$-dimensional, and produces a sequence of output vectors $\\mathbf t_1^n$, each $O$-dimensional and a summary vector $\\mathbf h \\in \\mathbb R^O$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf t_1^n, \\mathbf h = \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}})\n",
    "\\end{equation}\n",
    "\n",
    "where we use $\\theta_{\\text{enc}}$ to denote the subset of parameters in $\\theta$ that are specific to this encoder block. \n",
    "\n",
    "*Remark:* in practice for a correct batched implementation, our encoders also take a mask matrix and a vector of lengths.\n",
    "\n",
    "Examples of encoding functions can be a feed-forward NN (with an aggregator based on sum or average/max pooling) or a recurrent NN (e.g. an LSTM/GRU). Other architectures are also possible.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "From our summary vector $\\mathbf h$, we need to parameterise a categorical distribution over $K$ classes, thus we use\n",
    "\n",
    "\\begin{align}\n",
    "f(x; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where $\\text{dense}_K$ is a dense layer with $K=5$ outputs and $\\theta_{\\text{output}}$ corresponds to its parameters (weight matrix and bias vector). Note that we need to use the softmax activation function in order to guarantee that the output of $f$ is a normalised probability vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc15Nv2i41cq"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "To leave an indication of the shape of tensors in the code, we use the following convention\n",
    "\n",
    "```python\n",
    "[B, T, D]\n",
    "```\n",
    "\n",
    "where `B` stands for `batch_size`, `T` stands for `time` (or rather *maximum sequence length*), and `D` is the size of the representation.\n",
    "\n",
    "\n",
    "Consider the following abstract Encoder class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwEPXT2MWvYz",
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    An Encoder for us is a function that\n",
    "      1. transforms a sequence of I-dimensional vectors into a sequence of O-dimensional vectors\n",
    "      2. summarises a sequence of I-dimensional vectors into one O-dimensional vector\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        \"\"\"\n",
    "        The input is a batch-first tensor of token ids. Here is an example:\n",
    "        \n",
    "        Example of inputs (though rather than words, we have word ids):\n",
    "            INPUTS                     MASK       LENGTHS\n",
    "            [the nice cat -PAD-]    -> [1 1 1 0]  [3]\n",
    "            [the nice dog running]  -> [1 1 1 1]  [4]\n",
    "            \n",
    "        Note that:\n",
    "              mask =  inputs == 1\n",
    "              lengths = mask.sum(dim=-1)\n",
    "        \n",
    "        :param inputs: [B, T, I]\n",
    "        :param mask: [B, T]\n",
    "        :param lengths: [B]\n",
    "        :returns: [B, T, O], [B, O]\n",
    "            where the first tensor is the transformed input\n",
    "            and the second tensor is a summary of all inputs\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA5wmkcRg9Am"
   },
   "source": [
    "Let's start easy, implement a *bag of words* encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-9hLQ0lF5SG"
   },
   "outputs": [],
   "source": [
    "class BagOfWordsEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not transform the input sequence, \n",
    "     and its summary output is just a sum.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BagOfWordsEncoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths=None, **kwargs):\n",
    "        reshaped_mask = mask.float().unsqueeze(-1)  # shape: [B, T, 1]\n",
    "        return inputs, (inputs * reshaped_mask).sum(1) / (reshaped_mask.sum(1) + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS7x0hLrUXfN"
   },
   "source": [
    "You can also consider implementing\n",
    "\n",
    "* a feed-forward encoder with average pooling\n",
    "* and a biLSTM encoder\n",
    "\n",
    "but these are certainly optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpOGFpK_Uo0-"
   },
   "outputs": [],
   "source": [
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size, \n",
    "                 activation=None, \n",
    "                 hidden_sizes=[], \n",
    "                 aggregator='sum',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super(FFEncoder, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        def add_droput(name):\n",
    "            if dropout > 0:\n",
    "                layers.append((name, nn.Dropout(p=dropout)))\n",
    "        \n",
    "        if len(hidden_sizes) > 0:                    \n",
    "            for i, size in enumerate(hidden_sizes):\n",
    "                add_droput('dropout_{}'.format(i))\n",
    "                layers.append(('linear_{}'.format(i), nn.Linear(input_size, size)))\n",
    "                layers.append(('tanh_{}'.format(i), nn.Tanh()))\n",
    "                input_size = size\n",
    "\n",
    "        last_output_size = hidden_sizes[-1] if len(hidden_sizes) > 0 else input_size\n",
    "        add_droput('final_dropout')\n",
    "        layers.append(('final_linear', nn.Linear(last_output_size, output_size)))       \n",
    "        self.layer = nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "        if not aggregator in ['sum', 'avg']:\n",
    "            raise ValueError(\"I can only aggregate outputs using 'sum' or 'avg'\")\n",
    "        self.aggregator = aggregator\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        outputs = self.layer(inputs)  # shape: [B, T, O]\n",
    "        if not self.activation is None:\n",
    "            outputs = self.activation(outputs)  # shape: [B, T, O]\n",
    "        reshaped_mask = mask.float().unsqueeze(-1)  # shape: [B, T, 1]\n",
    "        summary = (outputs * reshaped_mask).sum(dim=1)  # shape: [B, O]\n",
    "        if self.aggregator == 'avg':\n",
    "            reshaped_lens = lengths.float().unsqueeze(-1)  # shape: [B, 1]\n",
    "            summary /= reshaped_lens  # shape: [B, O]\n",
    "        return outputs, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxQ5djZ_VAvK"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence into a single vector using an LSTM,\n",
    "     it also returns the hidden states at each time step.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_size: int=200,\n",
    "                 batch_first: bool=True,\n",
    "                 bidirectional: bool=True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            in_features,\n",
    "            hidden_size,\n",
    "            batch_first=batch_first,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, E]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        packed_sequence = pack_padded_sequence(x, lengths, batch_first=self.batch_first)\n",
    "        outputs, (hx, cx) = self.lstm(packed_sequence)\n",
    "        outputs, _ = pad_packed_sequence(outputs, batch_first=self.batch_first)\n",
    "\n",
    "        # classify from concatenation of final states\n",
    "        if self.lstm.bidirectional:\n",
    "            final = torch.cat([hx[-2], hx[-1]], dim=-1)\n",
    "        else:  # classify from final state\n",
    "            final = hx[-1]\n",
    "\n",
    "        return outputs, final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_zz5zIyVkSh"
   },
   "source": [
    "Here is some helper code to select and return an encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59ZU6JddVjMV"
   },
   "outputs": [],
   "source": [
    "def get_encoder(layer, in_features, hidden_size, bidirectional=True):\n",
    "    \"\"\"Returns the requested layer.\"\"\"\n",
    "\n",
    "    # TODO: make pass and average layers\n",
    "    if layer == \"bow\":\n",
    "        return BagOfWordsEncoder()\n",
    "    elif layer == 'ff':\n",
    "        return FFEncoder(\n",
    "            in_features, \n",
    "            2 * hidden_size,   # for convenience\n",
    "            hidden_sizes=[hidden_size], \n",
    "            aggregator='avg'\n",
    "        )\n",
    "    elif layer == \"lstm\":\n",
    "        return LSTMEncoder(\n",
    "            in_features, \n",
    "            hidden_size,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unknown layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY8LZiMN5CHW"
   },
   "source": [
    "# Sentiment Classification with Latent Rationale\n",
    "\n",
    "A latent rationale is a compact and informative fragment of the input based on which a NN classifier makes its decisions. [Lei et al (2016)](http://aclweb.org/anthology/D16-1011) proposed to induce such rationales along with a regression model for multi-aspect sentiment analsysis, their model is trained via REINFORCE on a dataset of beer reviews.\n",
    "\n",
    "*Remark:* the model we will develop here can be seen as a probabilistic version of their model. The rest of this notebook focus on our own probabilitisc view of the model.\n",
    "\n",
    "The picture below depicts our latent-variable model for rationale extraction:\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/rationale.png\"  height=\"200\">\n",
    "\n",
    "where we augment the model with a collection of latent variables $z = \\langle z_1, \\ldots, z_n\\rangle$ where $z_i$ is a binary latent variable. Each latent variable $z_i$ regulates whether or not the input $x_i$ is available to the classifier.  We use $x \\odot z$ to denote the selected words, which, in the terminology of Lei et al, is a latent rationale.\n",
    "\n",
    "Again the classifier parameterises a Categorical distribution over $K=5$ outcomes, though this time it can encode only a selection of the input:\n",
    "\n",
    "\\begin{align}\n",
    "    Z_i & \\sim \\text{Bern}(p_1) \\\\\n",
    "    Y|z,x &\\sim \\text{Cat}(f(x \\odot z; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where we have a shared and fixed Bernoulli prior (with parameter $p_1$) for all $n$ latent variables.\n",
    "\n",
    "\n",
    "Here is an example design for $f$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= z_i \\, \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}}) \\\\\n",
    "f(x \\odot z; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "* $z_i$ either leaves $\\mathbf x_i$ unchanged or turns it into a vector of zeros;\n",
    "* the encoder only sees features from selected inputs, i.e. $x_i$ for which $z_i = 1$;\n",
    "* $\\text{dense}_K$ is a linear layer with $K=5$ outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDHNxLHMWvY-"
   },
   "source": [
    "## Prior\n",
    "\n",
    "\n",
    "Our prior is a Bernoulli with fixed parameter $0 < p_1 < 1$:\n",
    "\n",
    "\\begin{align}\n",
    "Z_i & \\sim \\text{Bern}(p_1)\n",
    "\\end{align}\n",
    "\n",
    "whose pmf is $\\text{Bern}(z_i|p_1) = p_1^{z_i}\\times (1-p_1)^{1-z_i}$.\n",
    "\n",
    "As we will be using Bernoulli priors and posteriors, it is a good idea to implement a Bernoulli class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCBcHnTsOuDr"
   },
   "outputs": [],
   "source": [
    "class Bernoulli:\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) + pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf).    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1 / p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"probs:\", type(probs))\n",
    "        #print(\"logits:\", type(logits))\n",
    "                \n",
    "        if probs is None and logits is None:\n",
    "            raise ValueError('I need probabilities or logits')   \n",
    "        \n",
    "        self.probs = probs if logits is None else torch.sigmoid(logits)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a sample with the same shape as the parameters\"\"\"\n",
    "        return torch.bernoulli(self.probs)\n",
    "    \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample. \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        return x * torch.log(self.probs) + (1 - x) * torch.log(1. - self.probs)\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        return self.probs * (torch.log(self.probs) - torch.log(other.probs)) \\\n",
    "            + (1 - self.probs) * (torch.log(1 - self.probs) - torch.log(1 - other.probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0yfkCZlWvZP"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "The classifier encodes only a selection of the input, which we denote $x \\odot z$, and parameterises a Categorical distribution over $5$ outcomes (sentiment levels).\n",
    "\n",
    "Thus let's implement a Categorical distribution (we will only need to be able to assess its lgo pmf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-6JLDnBQcdg"
   },
   "outputs": [],
   "source": [
    "class Categorical:\n",
    "    \n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "        \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B] integers (targets)\n",
    "        :returns: [B] scalars (log probabilities)\n",
    "        \"\"\"\n",
    "        return torch.gather(self.log_probs, 1, x.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdrM_YRI8xBF"
   },
   "source": [
    "and a classifier architecture:\n",
    "\n",
    "* implement the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz7GaKbgRCd8"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed: nn.Embedding=None,\n",
    "                 hidden_size: int=200,\n",
    "                 output_size: int=1,\n",
    "                 dropout: float=0.1,\n",
    "                 layer: str=\"pass\"):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(embed)\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        :params x: [B, T, I] word representations\n",
    "        :params mask: [B, T] indicates valid positions\n",
    "        :params z: [B, T] binary selectors\n",
    "        :returns: one Categorical distribution per instance in the batch\n",
    "          each conditioning only on x_i for which z_i = 1\n",
    "        \"\"\"\n",
    "        embeddings = self.embed_layer(x)  # [B, T, E]\n",
    "        embedding_mask = z.float().unsqueeze(-1)  # [B, T, 1]\n",
    "        masked_embeddings = embeddings * embedding_mask  # [B, T, E]\n",
    "        lengths = mask.long().sum(1)\n",
    "\n",
    "        # encode the sentence\n",
    "        _, final = self.enc_layer(masked_embeddings, mask, lengths)\n",
    "\n",
    "        # predict sentiment from final state(s)\n",
    "        log_probs = self.output_layer(final)        \n",
    "        return Categorical(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2waCCBF9MaH"
   },
   "source": [
    "## Inference\n",
    "\n",
    "\n",
    "Computing the log-likelihood of an observation requires marginalising over assignments of $z$:\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x,\\theta,p_1) &= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 P(z|p_1)\\times P(y|x,z, \\theta) \\\\\n",
    "&= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 \\left( \\prod_{i=1}^n \\text{Bern}(z_i|p_1)\\right) \\times \\text{Cat}(y|f(x \\odot z; \\theta)) \n",
    "\\end{align}\n",
    "\n",
    "This is clearly intractable: there are $2^n$ possible assignments to $z$ and because the classifier conditions on all latent selectors, there's no way to simplify the expression.\n",
    "\n",
    "We will avoid computing this intractable marginal by instead employing an independently parameterised inference model.\n",
    "This inference model $Q(z|x, y, \\lambda)$ is an approximation to the true postrerior $P(z|x, y, \\theta, p_1)$, and we use $\\lambda$ to denote its parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jcVdYTg8Wun"
   },
   "source": [
    "We make a *mean field* assumption, whereby we model latent variables independently given the input:\n",
    "\\begin{align}\n",
    "Q(z|x, y, \\lambda) \n",
    "    &= \\prod_{i=1}^{n} Q(z_i|x; \\lambda) \\\\\n",
    "    &= \\prod_{i=1}^{n} \\text{Bern}(z_i|g_i(x; \\lambda)) \n",
    "\\end{align}\n",
    "\n",
    "where $g(x; \\lambda)$ is a NN that maps from $x = \\langle x_1, \\ldots, x_n\\rangle$ to $n$ Bernoulli parameters, each of which, is a probability value (thus $0 < g_i(x; \\lambda) < 1$).\n",
    "\n",
    "Note that though we could condition on $y$ for approximate posterior inference, we are opportunistically leaving it out. This way, $Q$ is directly available at test time for making predictions. The figure below is a graphical depiction of the inference model (we show a dashed arrow from $y$ to $z$ to remind you that in principle the label is also available).\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/inference.png\"  height=\"200\">\n",
    "\n",
    "Here is an example design for $g$:\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\lambda_{\\text{enc}}) \\\\\n",
    "g_i(x; \\lambda) &= \\sigma(\\text{dense}_1(\\mathbf t_i; \\lambda_{\\text{output}}))\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{glove}$ is a pre-trained embedding function;\n",
    "* $\\text{dense}_1$ is a dense layer with a single output;\n",
    "* and $\\sigma(\\cdot)$ is the sigmoid function, necessary to parameterise a Bernoulli distribution.\n",
    "\n",
    "From now on we will write $Q(z|x, \\lambda)$, that is, without $y.\n",
    "\n",
    "Here we implement this product of Bernoulli distributions:\n",
    "\n",
    "* implement $g$ in the constructor \n",
    "* and the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLxfcAbuSiFo"
   },
   "outputs": [],
   "source": [
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed: nn.Embedding,\n",
    "                 hidden_size: int=200,\n",
    "                 layer: str=\"bow\"):\n",
    "        \"\"\"\n",
    "        :param embed: an embedding layer\n",
    "        :param hidden_suze: hidden size for transformed inputs\n",
    "        :param layer: 'bow' for BoW encoding\n",
    "          you may alternatively implement and 'lstm' option\n",
    "          which uses a biLSTM to transform the inputs         \n",
    "        \"\"\"\n",
    "        super(ProductOfBernoullis, self).__init__()\n",
    "        # 1. we should have an embedding layer \n",
    "        # 2. we may transform the representations\n",
    "        # 3. and we should compute parameters for Bernoulli distributions\n",
    "        \n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(embed)\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(nn.Linear(enc_size, 1))\n",
    "        \n",
    "        self.report_params()\n",
    "    \n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "\n",
    "        #print(\"x:\", x.shape)\n",
    "        x = self.embed_layer(x)\n",
    "        #print(\"embed_layer:\", x.shape)\n",
    "        #print(\"mask:\", mask.shape)\n",
    "        _, x = self.enc_layer(x, mask)\n",
    "        #print(\"enc_layer:\", x.shape)\n",
    "        x = self.output_layer(x)\n",
    "        #print(\"output_layer:\", x.shape)\n",
    "        return Bernoulli(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcCu7vkKWvZX"
   },
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "In variational inference, our objective is to maximise the *evidence lowerbound* (ELBO):\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(y|x) &\\ge \\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\text{KL}(Q(z|x, y, \\lambda) || P(z|p_1)) \\\\\n",
    "\\text{ELBO}&\\overset{\\text{MF}}{=}\\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1)) \n",
    "\\end{align}\n",
    "\n",
    "where the *mean field* assumption we made implies that the KL term is simply a sum of KL divergences from a Bernoulli posterior to a Bernoulli prior.\n",
    "\n",
    "Note that the ELBO remains intractable, namely, solving the expectation in closed form still requires $2^n$ evaluations of the classifier network. Though unlike the true posterior $P(z|x,y, \\lambda)$, the approximation $Q(z|x,\\lambda)$ is tractable (it does not require an intractable normalisation) and can be used to obtain gradient estimates based on samples.\n",
    "\n",
    "### Gradient of the classifier network\n",
    "\n",
    "For the classifier, we encounter no problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\text{ELBO} &=\\nabla_\\theta\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\underbrace{\\nabla_\\theta \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{\\color{blue}{0}}  \\\\\n",
    "&=\\sum_{z} Q(z|x, \\lambda)\\nabla_\\theta\\log P(y|x,z,\\theta) \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\theta\\log P(y|x,z,\\theta) \\right] \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S \\nabla_\\theta \\log P(y|x, z^{(s)}, \\theta) \n",
    "\\end{align}\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$.\n",
    "\n",
    "\n",
    "### Gradient of the inference network\n",
    "\n",
    "For the inference model, we have to use the *score function estimator* (a.k.a. REINFORCE):\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\text{ELBO} &=\\nabla_\\lambda\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\nabla_\\lambda \\underbrace{\\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{ \\color{blue}{\\text{tractable} }}  \\\\\n",
    "&=\\sum_{z} \\nabla_\\lambda Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&=\\sum_{z}  \\underbrace{Q(z|x, \\lambda) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\nabla_\\lambda Q(z|x, \\lambda)} \\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(y|x,z,\\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) \\right] - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\left(\\frac{1}{S} \\sum_{s=1}^S  \\log P(y|x, z^{(s)}, \\theta) \\nabla_\\lambda \\log Q(z^{(s)}|x, \\lambda)  \\right) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))  \n",
    "\\end{align}\n",
    "\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cdfkOYdC0LQ"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Let's implement the model and the loss (negative ELBO). We work with the notion of a *surrogate loss*, that is, a computation node whose gradients wrt to parameters are equivalent to the gradients we need.\n",
    "\n",
    "For a given sample $z \\sim Q(z|x, \\lambda)$, the following is a single-sample surrogate loss:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal S(\\theta, \\lambda|x, y) = \\log P(y|x, z, \\theta) + \\color{red}{\\text{detach}(\\log P(y|x, z, \\theta) )}\\log Q(z|x, \\lambda) - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|\\phi))\n",
    "\\end{align}\n",
    "where we introduce an auxiliary function such that\n",
    "\\begin{align}\n",
    "\\text{detach}(f(\\alpha))  &= h(\\alpha) \\\\\n",
    "\\nabla_\\beta \\text{detach}(h(\\alpha))  &= 0 \n",
    "\\end{align}\n",
    "or in words, *detach* does not alter the forward call of its argument function $h$, but it alters $h$'s backward call by setting gradients to zero.\n",
    "\n",
    "Show that it's gradients wrt $\\theta$ and $\\lambda$ are exactly what we need:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FednEChaX6WI"
   },
   "source": [
    "\\begin{align}\n",
    "\\nabla_\\theta\\mathcal S(\\theta,\\lambda|x,y)=\\nabla_\\theta\\log P(y|x,z,\\theta)+0=\\nabla_\\theta\\text{ELBO}\n",
    "\\end{align}$$$$\\begin{align}\n",
    "\\nabla_\\lambda \\mathcal S(\\theta, \\lambda|x, y)= 0 + \\underbrace{\\log Q(z|x, \\lambda)\\nabla_\\lambda \\log P(y|x, z, \\theta)  + \\log P(y|x, z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\text{chain rule}}-\\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))=\\\\ \n",
    "= 0+ 0 + \\log P(y|x, z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)-\\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))=\\nabla_\\lambda\\text{ELBO}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaUMKDShx9T0"
   },
   "source": [
    "Implement the forward pass and loss below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cnwwk-7tfR02"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Classifier model:\n",
    "        Z_i ~ Bern(p_1) for i in 1..n\n",
    "        Y|x,z ~ Cat(f([x_i if z_i 1 else 0 for i in 1..n ]))\n",
    "    \n",
    "    Inference model:\n",
    "        Z_i|x ~ Bern(b_i) for i in 1..n\n",
    "            where b_i = g_i(x)\n",
    "    \n",
    "    Objective:\n",
    "        Single-sample MC estimate of ELBO\n",
    "    \n",
    "    Loss: \n",
    "        Surrogate loss\n",
    "\n",
    "    Consists of:\n",
    "        - a product of Bernoulli distributions inference network\n",
    "        - a classifier network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab: object = None,\n",
    "                 vocab_size: int = 0,\n",
    "                 emb_size: int = 200,\n",
    "                 hidden_size: int = 200,\n",
    "                 num_classes: int = 5,\n",
    "                 prior_p1: float = 0.3,                 \n",
    "                 det_prior: bool = True,\n",
    "                 beta_shape: list = [0.6, 0.6],\n",
    "                 dropout: float = 0.1,\n",
    "                 layer_cls: str = 'bow',\n",
    "                 layer_inf: str = 'bow'):\n",
    "        \"\"\"\n",
    "        :param vocab: Vocabulary\n",
    "        :param vocab_size: necessary for embedding layer\n",
    "        :param emb_size: dimensionality of embedding layer\n",
    "        :param hidden_size: dimensionality of hidden layers\n",
    "        :param num_classes: number of classes\n",
    "        :param prior_p1: (scalar) prior Bernoulli parameter\n",
    "        :param det_prior: (boolean) whether the prior parameter is deterministic\n",
    "        :param beta_shape: (pair of positive scalars) \n",
    "            when the prior parameter is stochastic\n",
    "            it is sampled from a Beta distribution (ignore this at first)\n",
    "        :param dropout: (scalar) dropout rate\n",
    "        :param layer_cls: type of encoder for classification\n",
    "        :param layer_inf: type of encoder for inference\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.embed = embed = nn.Embedding(vocab_size, emb_size, padding_idx=1)\n",
    "\n",
    "        self.cls_net = Classifier(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=num_classes,\n",
    "            dropout=dropout, \n",
    "            layer=layer_cls\n",
    "        )\n",
    "        \n",
    "        self.inference_net = ProductOfBernoullis(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size,\n",
    "            layer=layer_inf\n",
    "        )\n",
    "        \n",
    "        self._prior_p1 = prior_p1\n",
    "        self._det_prior = det_prior\n",
    "        self._beta_shape = beta_shape\n",
    "        \n",
    "    def get_prior_p1(self, p_min=0.001, p_max=0.999):\n",
    "        \"\"\"Return the prior Bernoulli parameter\"\"\"\n",
    "        if self._det_prior:\n",
    "            return torch.tensor(self._prior_p1)\n",
    "        else:\n",
    "            a, b = self._beta_shape\n",
    "            prior_p1 = np.random.beta(a, b)\n",
    "            prior_p1 = max(prior_p1, p_min)\n",
    "            prior_p1 = min(prior_p1, p_max)\n",
    "        return torch.tensor(prior_p1)\n",
    "\n",
    "    def predict(self, py: Categorical, **kwargs):\n",
    "        \"\"\"\n",
    "        Predict deterministically using argmax.\n",
    "        :param py: B Categorical distributions (one per instance in batch)\n",
    "        :return: predictions\n",
    "            [B] sentiment levels\n",
    "        \"\"\"\n",
    "        assert not self.training, \"should be in eval mode for prediction\"\n",
    "        return py.log_probs.argmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Generate a sequence z with inference model, \n",
    "         then predict with rationale xz, that is, x masked by z.\n",
    "\n",
    "        :param x: [B, T] documents        \n",
    "        :param mask: [B, T] indicates valid positions vs padded positions\n",
    "        :return: \n",
    "            Categorical distributions P(y|x, z)\n",
    "            Bernoulli distributions Q(z|x)\n",
    "            Single sample z ~ Q(z|x) used for the conditional P(y|x, z)\n",
    "        \"\"\"\n",
    "        bern = self.inference_net(x, x != 1)\n",
    "        z = bern.sample()\n",
    "        res = self.cls_net(x, x != 1, z)\n",
    "        return res, bern, z\n",
    "\n",
    "    def get_loss(self,                   \n",
    "                 y, \n",
    "                 py: Categorical,\n",
    "                 qz: Bernoulli, \n",
    "                 z, \n",
    "                 mask,\n",
    "                 iter_i=0, \n",
    "                 # you may ignore the rest of the arguments for the time being\n",
    "                 #  leave them as they are\n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This computes the loss for the whole model.\n",
    "\n",
    "        :param y: target labels [B]\n",
    "        :param py: conditionals P(y|x, z)\n",
    "        :param qz: approximate posteriors Q(z|x)\n",
    "        :param z: sample of binary selectors [B, T]\n",
    "        :param mask: indicates valid positions [B, T]\n",
    "        :param iter_i: indicates the iteration\n",
    "        :param kl_weight: (scalar) multiplies the KL term\n",
    "        :param min_kl: (scalar) sets a minimum for the KL (aka free bits)\n",
    "        :param ll_mean: (scalar) running average of reward\n",
    "        :param ll_std: (scalar) running standard deviation of reward\n",
    "        :return: loss (torch node), terms (dict)\n",
    "        \n",
    "            terms is an OrderedDict that holds the scalar items involved in the loss\n",
    "            e.g. `terms['ll'] = ll.item()` is the log-likelihood term\n",
    "            \n",
    "            Consider tracking the following:\n",
    "            Single-sample ELBO: terms['elbo']\n",
    "            Log-Likelihood log P(y|x,z): terms['ll']\n",
    "            KL: terms['kl']\n",
    "            Score function surrogate log P(y|z, x) log Q(z|x): terms['sf']            \n",
    "            Rate of selected words: terms['selected']\n",
    "        \"\"\"\n",
    "        ll = py.log_pmf(y)\n",
    "        kl = qz.kl(Bernoulli(probs=self.get_prior_p1()))\n",
    "        sf = qz.log_pmf(z.type(torch.FloatTensor)) * (ll.detach() - ll_mean) / ll_std\n",
    "        loss =  ll + sf - kl_weight * kl\n",
    "        \n",
    "        terms = OrderedDict()\n",
    "        terms['elbo'] = (ll - kl).sum().item()\n",
    "        terms['sf'] = sf.sum().item()\n",
    "        terms['selected'] = z.sum().item() * 1.0 / z.shape[0] / z.shape[1]\n",
    "        terms['kl'] = kl.sum().item()\n",
    "        terms['ll'] = ll=ll.sum().item()\n",
    "        \n",
    "        return -loss.sum(), terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNQDXTpqWvZa"
   },
   "outputs": [],
   "source": [
    "# This will be used later for maintaining runnin averages of quantites like \n",
    "#  terms in the ELBO\n",
    "from collections import deque\n",
    "\n",
    "class MovingStats:\n",
    "    \n",
    "    def __init__(self, memory=-1):\n",
    "        self.data = deque([])\n",
    "        self.memory = memory\n",
    "        \n",
    "    def append(self, value):\n",
    "        if self.memory != 0:\n",
    "            if self.memory > 0 and len(self.data) == self.memory:\n",
    "                self.data.popleft()\n",
    "            self.data.append(value)\n",
    "        \n",
    "    def mean(self):\n",
    "        if len(self.data):\n",
    "            return np.mean([x for x in self.data])\n",
    "        else:\n",
    "            return 0.\n",
    "    \n",
    "    def std(self):\n",
    "        return np.std(self.data) if len(self.data) > 1 else 1.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "081YSfU9WvZc"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Pc80gseWvZd"
   },
   "outputs": [],
   "source": [
    "# some helper code for mini batching\n",
    "#  this will take care of annoying things such as \n",
    "#  sorting training instances by length (necessary for pytorch's LSTM, for example)\n",
    "from sst.util import make_kv_string, get_minibatch, prepare_minibatch, print_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WVr97kilIRV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Configuration\n",
      "training_path        : ../sst/data/sst/train.txt\n",
      "dev_path             : ../sst/data/sst/dev.txt\n",
      "test_path            : ../sst/data/sst/test.txt\n",
      "word_vectors         : ../sst/data/sst/glove.840B.300d.filtered.txt\n",
      "prior_p1             :        0.3\n",
      "beta_a               :        0.6\n",
      "beta_b               :        0.6\n",
      "det_prior            :          1\n",
      "num_epochs           :         50\n",
      "print_every          :        100\n",
      "eval_every           :         -1\n",
      "batch_size           :         25\n",
      "eval_batch_size      :         25\n",
      "subphrases           :          0\n",
      "min_phrase_length    :          2\n",
      "lowercase            :          1\n",
      "fix_emb              :          1\n",
      "embed_size           :        300\n",
      "hidden_size          :        150\n",
      "num_layers           :          1\n",
      "dropout              :        0.5\n",
      "layer_inf            : bow       \n",
      "layer_cls            : bow       \n",
      "save_path            : data/results\n",
      "baseline_memory      :       1000\n",
      "min_kl               :        0.0\n",
      "kl_weight            :        1.0\n",
      "kl_inc               :      1e-05\n",
      "lr                   :     0.0002\n",
      "weight_decay         :      1e-05\n",
      "lr_decay             :        0.5\n",
      "patience             :          5\n",
      "cooldown             :          5\n",
      "threshold            :     0.0001\n",
      "min_lr               :      1e-05\n",
      "max_grad_norm        :        5.0\n",
      "Set eval_every to 341\n",
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Example\n",
      "First dev example: Example(tokens=['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "# We will use Adam\n",
    "from torch.optim import Adam\n",
    "# and a couple of tricks to reduce learning rate on plateau\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# here is some helper code to evaluate your model\n",
    "from sst.evaluate import evaluate\n",
    "\n",
    "\n",
    "cfg = dict()\n",
    "\n",
    "# Data\n",
    "cfg['training_path'] = \"../sst/data/sst/train.txt\"\n",
    "cfg['dev_path'] = \"../sst/data/sst/dev.txt\"\n",
    "cfg['test_path'] = \"../sst/data/sst/test.txt\"\n",
    "cfg['word_vectors'] = '../sst/data/sst/glove.840B.300d.filtered.txt'\n",
    "# Model\n",
    "cfg['prior_p1'] = 0.3\n",
    "cfg['beta_a'] = 0.6\n",
    "cfg['beta_b'] = 0.6\n",
    "cfg['det_prior'] = True\n",
    "# Architecture\n",
    "cfg['num_epochs'] = 50\n",
    "cfg['print_every'] = 100\n",
    "cfg['eval_every'] = -1\n",
    "cfg['batch_size'] = 25\n",
    "cfg['eval_batch_size'] = 25\n",
    "cfg['subphrases'] = False\n",
    "cfg['min_phrase_length'] = 2\n",
    "cfg['lowercase'] = True\n",
    "cfg['fix_emb'] = True\n",
    "cfg['embed_size'] = 300\n",
    "cfg['hidden_size'] = 150\n",
    "cfg['num_layers'] = 1\n",
    "cfg['dropout'] = 0.5\n",
    "cfg['layer_inf'] = 'bow'\n",
    "cfg['layer_cls'] = 'bow'\n",
    "cfg['save_path'] = 'data/results'\n",
    "cfg['baseline_memory'] = 1000\n",
    "cfg['min_kl'] = 0.  # use more than 0 to enable free bits\n",
    "cfg['kl_weight'] = 1.  # start from zero to enable annealing\n",
    "cfg['kl_inc'] = 0.00001  \n",
    "# Optimiser (leave as is)\n",
    "cfg['lr'] = 0.0002\n",
    "cfg['weight_decay'] = 1e-5\n",
    "cfg['lr_decay'] = 0.5\n",
    "cfg['patience'] = 5\n",
    "cfg['cooldown'] = 5\n",
    "cfg['threshold'] = 1e-4\n",
    "cfg['min_lr'] = 1e-5\n",
    "cfg['max_grad_norm'] = 5.\n",
    "\n",
    "\n",
    "print('# Configuration')\n",
    "for k, v in cfg.items():\n",
    "    print(\"{:20} : {:10}\".format(k, v))\n",
    "\n",
    "\n",
    "iters_per_epoch = len(train_data) // cfg[\"batch_size\"]\n",
    "\n",
    "if cfg[\"eval_every\"] == -1:\n",
    "    eval_every = iters_per_epoch\n",
    "    print(\"Set eval_every to {}\".format(iters_per_epoch))\n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader(\n",
    "    cfg['training_path'],\n",
    "    lower=cfg['lowercase'], \n",
    "    subphrases=cfg['subphrases'],\n",
    "    min_length=cfg['min_phrase_length']))\n",
    "dev_data = list(examplereader(cfg['dev_path'], lower=cfg['lowercase']))\n",
    "test_data = list(examplereader(cfg['test_path'], lower=cfg['lowercase']))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Example')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PMqtVj0WvZf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    # Create a vocabulary object to map str <-> int\n",
    "    vocab = Vocabulary()  # populated by load_glove\n",
    "    glove_path = cfg[\"word_vectors\"]\n",
    "    vectors = load_glove(glove_path, vocab)\n",
    "\n",
    "    # You may consider using tensorboardX\n",
    "    # writer = SummaryWriter(log_dir=cfg[\"save_path\"])\n",
    "\n",
    "    # Map the sentiment labels 0-4 to a more readable form (and the opposite)\n",
    "    i2t = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
    "    t2i = OrderedDict({p: i for p, i in zip(i2t, range(len(i2t)))})\n",
    "\n",
    "\n",
    "    print('\\n# Constructing model')\n",
    "    model = Model(\n",
    "        vocab_size=len(vocab.w2i), \n",
    "        emb_size=cfg[\"embed_size\"],\n",
    "        hidden_size=cfg[\"hidden_size\"], \n",
    "        num_classes=len(t2i),\n",
    "        prior_p1=cfg['prior_p1'],\n",
    "        det_prior=cfg['det_prior'],\n",
    "        beta_shape=[cfg['beta_a'], cfg['beta_b']],\n",
    "        vocab=vocab, \n",
    "        dropout=cfg[\"dropout\"], \n",
    "        layer_cls=cfg[\"layer_cls\"],\n",
    "        layer_inf=cfg[\"layer_inf\"]\n",
    "    )\n",
    "\n",
    "    print('\\n# Loading embeddings')\n",
    "    with torch.no_grad():\n",
    "        model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "        if cfg[\"fix_emb\"]:\n",
    "            print(\"fixed word embeddings\")\n",
    "            model.embed.weight.requires_grad = False\n",
    "        model.embed.weight[1] = 0.  # padding zero\n",
    "\n",
    "        \n",
    "    # Congigure optimiser\n",
    "    optimizer = Adam(model.parameters(), lr=cfg[\"lr\"],\n",
    "                     weight_decay=cfg[\"weight_decay\"])\n",
    "    # and learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "        verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "        min_lr=cfg[\"min_lr\"])\n",
    "\n",
    "    # Prepare a few auxiliary variables\n",
    "    iter_i = 0\n",
    "    train_loss = 0.\n",
    "    print_num = 0\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    best_eval = 1.0e9\n",
    "    best_iter = 0\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Some debugging info\n",
    "    print(model)\n",
    "    print_parameters(model)\n",
    "\n",
    "    batch_size = cfg['batch_size']\n",
    "    eval_batch_size = cfg['eval_batch_size']\n",
    "    print_every = cfg['print_every']\n",
    "\n",
    "    # Parameters of tricks to better optimise the ELBO \n",
    "    kl_inc = cfg['kl_inc']\n",
    "    kl_weight = cfg['kl_weight']\n",
    "    min_kl = cfg['min_kl']\n",
    "    # Running estimates for baselines\n",
    "    ll_moving_stats = MovingStats(cfg['baseline_memory'])\n",
    "\n",
    "    while True:  # when we run out of examples, shuffle and continue\n",
    "        epoch = iter_i // iters_per_epoch\n",
    "        if epoch > cfg['num_epochs']:\n",
    "            break\n",
    "        \n",
    "        for batch in get_minibatch(train_data, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "            epoch = iter_i // iters_per_epoch\n",
    "            if epoch > cfg['num_epochs']:\n",
    "                break\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            x, y, _ = prepare_minibatch(batch, model.vocab, device=device)\n",
    "            \n",
    "            mask = (x != 1)\n",
    "            py, qz, z = model(x)\n",
    "\n",
    "            # \"KL annealing\"\n",
    "            kl_weight += kl_inc\n",
    "            if kl_weight > 1.:\n",
    "                kl_weight = 1.0\n",
    "                \n",
    "            loss, terms = model.get_loss(\n",
    "                y,\n",
    "                py=py, \n",
    "                qz=qz,\n",
    "                z=z,\n",
    "                mask=mask, \n",
    "                kl_weight=kl_weight,\n",
    "                min_kl=min_kl,\n",
    "                ll_mean=ll_moving_stats.mean(),\n",
    "                ll_std=ll_moving_stats.std(),\n",
    "                iter_i=iter_i)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # keep an running estimate of the reward (log P(y|x,z))\n",
    "            ll_moving_stats.append(terms['ll'])\n",
    "\n",
    "            # backward pass\n",
    "            model.zero_grad()  # erase previous gradients\n",
    "\n",
    "            loss.backward()  # compute new gradients\n",
    "\n",
    "            # gradient clipping generally helps\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['max_grad_norm'])\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            print_num += 1\n",
    "            iter_i += 1\n",
    "\n",
    "            # print info\n",
    "            if iter_i % print_every == 0:\n",
    "\n",
    "                train_loss = train_loss / print_every\n",
    "\n",
    "                print_str = make_kv_string(terms)\n",
    "                print(\"Epoch %r Iter %r loss=%.4f %s\" %\n",
    "                      (epoch, iter_i, train_loss, print_str))\n",
    "                losses.append(train_loss)\n",
    "                print_num = 0\n",
    "                train_loss = 0.\n",
    "\n",
    "            # evaluate\n",
    "            if iter_i % eval_every == 0:\n",
    "\n",
    "                dev_eval, rationales = evaluate(\n",
    "                    model, dev_data, \n",
    "                    batch_size=eval_batch_size, \n",
    "                    device=device,\n",
    "                    cfg=cfg, iter_i=iter_i\n",
    "                )\n",
    "                accuracies.append(dev_eval[\"acc\"])\n",
    "\n",
    "                print(\"\\n# epoch %r iter %r: dev %s\" % (\n",
    "                    epoch, iter_i, make_kv_string(dev_eval)))\n",
    "                \n",
    "                for exid in range(3):\n",
    "                    print(' dev%d [gold=%d,pred=%d]:' % (exid, dev_data[exid].label, rationales[exid][1]),  \n",
    "                          ' '.join(rationales[exid][0]))\n",
    "                print()\n",
    "\n",
    "                # adjust learning rate\n",
    "                scheduler.step(dev_eval[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5uYKcw-WvZl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Constructing model\n",
      "Classifier #params: 1505\n",
      "ProductOfBernoullis #params: 301\n",
      "\n",
      "# Loading embeddings\n",
      "fixed word embeddings\n",
      "Model(\n",
      "  (embed): Embedding(20727, 300, padding_idx=1)\n",
      "  (cls_net): Classifier(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): BagOfWordsEncoder()\n",
      "    (output_layer): Sequential(\n",
      "      (0): Dropout(p=0.5)\n",
      "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
      "      (2): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (inference_net): ProductOfBernoullis(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): BagOfWordsEncoder()\n",
      "    (output_layer): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "embed.weight             [20727, 300] requires_grad=False\n",
      "cls_net.output_layer.1.weight [5, 300]     requires_grad=True\n",
      "cls_net.output_layer.1.bias [5]          requires_grad=True\n",
      "inference_net.output_layer.0.weight [1, 300]     requires_grad=True\n",
      "inference_net.output_layer.0.bias [1]          requires_grad=True\n",
      "\n",
      "Total parameters: 6219906\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 0 Iter 100 loss=1658.3010 elbo -42.1408 sf -1543.6965 selected 0.5200 kl 1.2396 ll -40.9012\n",
      "Epoch 0 Iter 200 loss=1521.1138 elbo -41.1405 sf -1383.4025 selected 0.2400 kl 1.1524 ll -39.9881\n",
      "Epoch 0 Iter 300 loss=1455.9919 elbo -41.5273 sf -1401.1321 selected 0.5200 kl 1.3554 ll -40.1719\n",
      "\n",
      "# epoch 0 iter 341: dev loss 13.6635 elbo -40.9632 sf 27.2997 selected 0.4460 kl 1.1265 ll -39.8366 acc 0.2025\n",
      " dev0 [gold=3,pred=0]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=0]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 1 Iter 400 loss=1104.8008 elbo -40.8207 sf -856.6323 selected 0.4000 kl 1.2248 ll -39.5959\n",
      "Epoch 1 Iter 500 loss=903.7708 elbo -40.0741 sf -877.3226 selected 0.5600 kl 1.1841 ll -38.8899\n",
      "Epoch 1 Iter 600 loss=884.4605 elbo -40.1131 sf -829.9720 selected 0.4000 kl 1.1923 ll -38.9208\n",
      "\n",
      "# epoch 1 iter 682: dev loss 13.2102 elbo -40.2987 sf 27.0885 selected 0.4632 kl 1.0072 ll -39.2915 acc 0.3006\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 2 Iter 700 loss=840.9278 elbo -38.8547 sf -735.1158 selected 0.4400 kl 0.9860 ll -37.8687\n",
      "Epoch 2 Iter 800 loss=751.9666 elbo -40.9754 sf -724.3687 selected 0.5200 kl 0.8489 ll -40.1265\n",
      "Epoch 2 Iter 900 loss=733.0543 elbo -39.4308 sf -673.1004 selected 0.4400 kl 0.7460 ll -38.6848\n",
      "Epoch 2 Iter 1000 loss=720.5748 elbo -40.4408 sf -648.4401 selected 0.3200 kl 0.8202 ll -39.6207\n",
      "\n",
      "# epoch 2 iter 1023: dev loss 13.4828 elbo -39.9315 sf 26.4487 selected 0.4178 kl 0.7558 ll -39.1757 acc 0.2943\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=1]: **no**\n",
      " dev2 [gold=3,pred=1]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 3 Iter 1100 loss=676.8302 elbo -40.4940 sf -614.8094 selected 0.4000 kl 0.6924 ll -39.8016\n",
      "Epoch 3 Iter 1200 loss=657.8175 elbo -40.6146 sf -622.5807 selected 0.4400 kl 0.7784 ll -39.8362\n",
      "Epoch 3 Iter 1300 loss=649.4973 elbo -39.6994 sf -611.7964 selected 0.5200 kl 0.8668 ll -38.8326\n",
      "\n",
      "# epoch 3 iter 1364: dev loss 13.5863 elbo -39.7895 sf 26.2032 selected 0.4124 kl 0.9057 ll -38.8838 acc 0.3097\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=1]: no\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 4 Iter 1400 loss=635.6358 elbo -39.4877 sf -580.5654 selected 0.4000 kl 0.9459 ll -38.5418\n",
      "Epoch 4 Iter 1500 loss=616.4370 elbo -40.4015 sf -535.8801 selected 0.2800 kl 0.8784 ll -39.5231\n",
      "Epoch 4 Iter 1600 loss=610.8582 elbo -38.3745 sf -573.5749 selected 0.4400 kl 0.9494 ll -37.4251\n",
      "Epoch 4 Iter 1700 loss=604.5397 elbo -37.9837 sf -594.4601 selected 0.4800 kl 0.9042 ll -37.0794\n",
      "\n",
      "# epoch 4 iter 1705: dev loss 13.3198 elbo -39.6140 sf 26.2942 selected 0.4278 kl 0.8585 ll -38.7555 acc 0.3025\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 5 Iter 1800 loss=592.2914 elbo -39.5706 sf -547.3264 selected 0.4000 kl 0.7522 ll -38.8184\n",
      "Epoch 5 Iter 1900 loss=587.1000 elbo -39.7488 sf -507.8483 selected 0.2800 kl 0.7553 ll -38.9934\n",
      "Epoch 5 Iter 2000 loss=590.7688 elbo -40.0408 sf -524.4495 selected 0.3600 kl 0.8077 ll -39.2331\n",
      "\n",
      "# epoch 5 iter 2046: dev loss 12.9742 elbo -39.3696 sf 26.3955 selected 0.4387 kl 0.6993 ll -38.6703 acc 0.2988\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 6 Iter 2100 loss=589.1672 elbo -37.8149 sf -539.4609 selected 0.4000 kl 0.7095 ll -37.1054\n",
      "Epoch 6 Iter 2200 loss=590.8777 elbo -39.1523 sf -565.0474 selected 0.4800 kl 0.8064 ll -38.3459\n",
      "Epoch 6 Iter 2300 loss=581.3685 elbo -40.2674 sf -523.6077 selected 0.3200 kl 0.7325 ll -39.5349\n",
      "\n",
      "# epoch 6 iter 2387: dev loss 13.3467 elbo -39.2002 sf 25.8535 selected 0.4114 kl 0.6625 ll -38.5377 acc 0.2952\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 7 Iter 2400 loss=580.3556 elbo -39.4130 sf -514.7589 selected 0.3200 kl 0.6817 ll -38.7313\n",
      "Epoch 7 Iter 2500 loss=576.1243 elbo -38.9932 sf -506.7018 selected 0.2800 kl 0.5244 ll -38.4688\n",
      "Epoch 7 Iter 2600 loss=571.0626 elbo -37.3751 sf -511.5482 selected 0.3200 kl 0.3618 ll -37.0133\n",
      "Epoch 7 Iter 2700 loss=561.1598 elbo -38.9015 sf -500.8865 selected 0.3200 kl 0.3705 ll -38.5310\n",
      "\n",
      "# epoch 7 iter 2728: dev loss 13.1294 elbo -38.7015 sf 25.5721 selected 0.4087 kl 0.3923 ll -38.3092 acc 0.3025\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 8 Iter 2800 loss=564.7650 elbo -38.8179 sf -485.4790 selected 0.2800 kl 0.3703 ll -38.4476\n",
      "Epoch 8 Iter 2900 loss=567.5286 elbo -37.1589 sf -516.6226 selected 0.3600 kl 0.4603 ll -36.6987\n",
      "Epoch 8 Iter 3000 loss=551.9615 elbo -37.6161 sf -537.3347 selected 0.4400 kl 0.3772 ll -37.2389\n",
      "\n",
      "# epoch 8 iter 3069: dev loss 13.5072 elbo -38.7541 sf 25.2469 selected 0.3824 kl 0.3462 ll -38.4078 acc 0.2952\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 9 Iter 3100 loss=548.4061 elbo -37.1952 sf -512.3548 selected 0.4000 kl 0.4047 ll -36.7905\n",
      "Epoch 9 Iter 3200 loss=530.7802 elbo -37.9058 sf -457.4643 selected 0.3200 kl 0.3087 ll -37.5970\n",
      "Epoch 9 Iter 3300 loss=518.8497 elbo -39.0681 sf -441.7604 selected 0.2800 kl 0.2236 ll -38.8446\n",
      "Epoch 9 Iter 3400 loss=516.4152 elbo -39.5368 sf -437.4046 selected 0.2800 kl 0.1843 ll -39.3525\n",
      "\n",
      "# epoch 9 iter 3410: dev loss 13.7821 elbo -38.5402 sf 24.7581 selected 0.3660 kl 0.1780 ll -38.3622 acc 0.2934\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 10 Iter 3500 loss=515.4646 elbo -39.2816 sf -440.8684 selected 0.2800 kl 0.1995 ll -39.0821\n",
      "Epoch 10 Iter 3600 loss=511.4227 elbo -39.2498 sf -437.6748 selected 0.2800 kl 0.1974 ll -39.0524\n",
      "Epoch 10 Iter 3700 loss=506.7431 elbo -36.7450 sf -481.7040 selected 0.4000 kl 0.2452 ll -36.4998\n",
      "\n",
      "# epoch 10 iter 3751: dev loss 14.1626 elbo -38.3486 sf 24.1861 selected 0.3515 kl 0.1765 ll -38.1722 acc 0.2988\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 11 Iter 3800 loss=506.4230 elbo -39.0185 sf -482.3774 selected 0.4000 kl 0.2356 ll -38.7829\n",
      "Epoch 11 Iter 3900 loss=502.4903 elbo -37.8117 sf -508.6506 selected 0.4400 kl 0.1919 ll -37.6197\n",
      "Epoch 11 Iter 4000 loss=504.5959 elbo -40.7861 sf -475.3984 selected 0.3600 kl 0.1909 ll -40.5951\n",
      "\n",
      "# epoch 11 iter 4092: dev loss 14.3565 elbo -38.1634 sf 23.8068 selected 0.3460 kl 0.1037 ll -38.0596 acc 0.2970\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Epoch    11: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 12 Iter 4100 loss=503.7464 elbo -38.7872 sf -557.8719 selected 0.4800 kl 0.1155 ll -38.6717\n",
      "Shuffling training data\n",
      "Epoch 12 Iter 4200 loss=501.4181 elbo -36.9044 sf -450.9806 selected 0.3200 kl 0.0754 ll -36.8290\n",
      "Epoch 12 Iter 4300 loss=485.0762 elbo -37.4371 sf -462.8214 selected 0.3200 kl 0.0851 ll -37.3520\n",
      "Epoch 12 Iter 4400 loss=479.9344 elbo -38.8223 sf -368.2747 selected 0.2000 kl 0.1033 ll -38.7190\n",
      "\n",
      "# epoch 12 iter 4433: dev loss 14.4403 elbo -38.3932 sf 23.9530 selected 0.3388 kl 0.0774 ll -38.3159 acc 0.2925\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Iter 4500 loss=479.7607 elbo -37.8035 sf -404.8511 selected 0.2800 kl 0.0660 ll -37.7375\n",
      "Epoch 13 Iter 4600 loss=474.3575 elbo -40.2181 sf -472.8783 selected 0.4000 kl 0.0659 ll -40.1522\n",
      "Epoch 13 Iter 4700 loss=463.4751 elbo -39.8135 sf -455.6486 selected 0.3600 kl 0.0602 ll -39.7533\n",
      "\n",
      "# epoch 13 iter 4774: dev loss 14.6294 elbo -38.2205 sf 23.5911 selected 0.3315 kl 0.0707 ll -38.1498 acc 0.2925\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 14 Iter 4800 loss=461.7234 elbo -40.4117 sf -397.7754 selected 0.2400 kl 0.0770 ll -40.3347\n",
      "Epoch 14 Iter 4900 loss=451.9144 elbo -39.4201 sf -327.5697 selected 0.1600 kl 0.0610 ll -39.3591\n",
      "Epoch 14 Iter 5000 loss=443.2918 elbo -39.9811 sf -339.5936 selected 0.2000 kl 0.0595 ll -39.9216\n",
      "Epoch 14 Iter 5100 loss=433.7386 elbo -39.0065 sf -432.3525 selected 0.3600 kl 0.0324 ll -38.9741\n",
      "\n",
      "# epoch 14 iter 5115: dev loss 14.8851 elbo -38.1811 sf 23.2960 selected 0.3270 kl 0.0446 ll -38.1365 acc 0.3079\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 15 Iter 5200 loss=445.8509 elbo -39.5700 sf -348.8616 selected 0.2000 kl 0.0469 ll -39.5231\n",
      "Epoch 15 Iter 5300 loss=451.0337 elbo -36.3390 sf -522.4045 selected 0.5600 kl 0.0644 ll -36.2746\n",
      "Epoch 15 Iter 5400 loss=443.9401 elbo -39.4006 sf -384.6669 selected 0.2800 kl 0.0570 ll -39.3436\n",
      "\n",
      "# epoch 15 iter 5456: dev loss 15.0566 elbo -38.3554 sf 23.2989 selected 0.3134 kl 0.0396 ll -38.3159 acc 0.2897\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 16 Iter 5500 loss=433.5626 elbo -40.2561 sf -292.6354 selected 0.1200 kl 0.0337 ll -40.2224\n",
      "Epoch 16 Iter 5600 loss=433.7640 elbo -38.3767 sf -361.2863 selected 0.2400 kl 0.0527 ll -38.3239\n",
      "Epoch 16 Iter 5700 loss=435.1229 elbo -41.0759 sf -333.9871 selected 0.2000 kl 0.0232 ll -41.0526\n",
      "\n",
      "# epoch 16 iter 5797: dev loss 16.0045 elbo -38.2696 sf 22.2651 selected 0.2888 kl 0.0352 ll -38.2344 acc 0.2906\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: **and**\n",
      "\n",
      "Epoch 17 Iter 5800 loss=436.5176 elbo -38.3838 sf -470.2181 selected 0.4400 kl 0.0522 ll -38.3316\n",
      "Shuffling training data\n",
      "Epoch 17 Iter 5900 loss=437.4615 elbo -37.5210 sf -377.9852 selected 0.2800 kl 0.0277 ll -37.4932\n",
      "Epoch 17 Iter 6000 loss=432.9122 elbo -37.6391 sf -448.8556 selected 0.4000 kl 0.0704 ll -37.5687\n",
      "Epoch 17 Iter 6100 loss=432.6082 elbo -34.7994 sf -414.0526 selected 0.3200 kl 0.0298 ll -34.7696\n",
      "\n",
      "# epoch 17 iter 6138: dev loss 14.9845 elbo -38.2093 sf 23.2249 selected 0.3197 kl 0.0356 ll -38.1737 acc 0.2879\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 18 Iter 6200 loss=437.1963 elbo -36.5605 sf -385.0080 selected 0.2800 kl 0.0253 ll -36.5351\n",
      "Epoch 18 Iter 6300 loss=437.3579 elbo -40.5311 sf -337.7437 selected 0.2000 kl 0.0392 ll -40.4918\n",
      "Epoch 18 Iter 6400 loss=431.6358 elbo -38.2696 sf -445.3320 selected 0.4000 kl 0.0366 ll -38.2330\n",
      "\n",
      "# epoch 18 iter 6479: dev loss 16.4543 elbo -38.4359 sf 21.9815 selected 0.2707 kl 0.0376 ll -38.3982 acc 0.2861\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 19 Iter 6500 loss=429.8706 elbo -40.3257 sf -375.3383 selected 0.2800 kl 0.0633 ll -40.2623\n",
      "Epoch 19 Iter 6600 loss=426.9718 elbo -37.6118 sf -359.8575 selected 0.2400 kl 0.0508 ll -37.5610\n",
      "Epoch 19 Iter 6700 loss=431.0636 elbo -41.0575 sf -431.2796 selected 0.3600 kl 0.0693 ll -40.9882\n",
      "Epoch 19 Iter 6800 loss=428.2749 elbo -38.5009 sf -362.2525 selected 0.2400 kl 0.0331 ll -38.4679\n",
      "\n",
      "# epoch 19 iter 6820: dev loss 15.9999 elbo -38.2764 sf 22.2765 selected 0.2916 kl 0.0497 ll -38.2267 acc 0.2952\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 20 Iter 6900 loss=434.0346 elbo -39.0548 sf -361.6960 selected 0.2400 kl 0.0596 ll -38.9952\n",
      "Epoch 20 Iter 7000 loss=437.4883 elbo -40.2409 sf -397.3793 selected 0.2800 kl 0.0447 ll -40.1962\n",
      "Epoch 20 Iter 7100 loss=431.3116 elbo -37.0287 sf -374.3468 selected 0.2400 kl 0.0412 ll -36.9875\n",
      "\n",
      "# epoch 20 iter 7161: dev loss 15.8383 elbo -38.2147 sf 22.3764 selected 0.2916 kl 0.0443 ll -38.1703 acc 0.2879\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 21 Iter 7200 loss=428.2695 elbo -36.1165 sf -361.6495 selected 0.2400 kl 0.0501 ll -36.0663\n",
      "Epoch 21 Iter 7300 loss=417.4272 elbo -39.7685 sf -382.6366 selected 0.3200 kl 0.0716 ll -39.6969\n",
      "Epoch 21 Iter 7400 loss=415.4327 elbo -36.8633 sf -404.4816 selected 0.3600 kl 0.0572 ll -36.8061\n",
      "Epoch 21 Iter 7500 loss=416.0764 elbo -39.4816 sf -348.5164 selected 0.2400 kl 0.0335 ll -39.4480\n",
      "\n",
      "# epoch 21 iter 7502: dev loss 16.1686 elbo -38.3844 sf 22.2158 selected 0.2870 kl 0.0397 ll -38.3447 acc 0.2843\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 22 Iter 7600 loss=402.4938 elbo -38.8834 sf -411.3271 selected 0.4000 kl 0.0379 ll -38.8455\n",
      "Epoch 22 Iter 7700 loss=395.7209 elbo -38.8893 sf -328.3337 selected 0.2400 kl 0.0346 ll -38.8547\n",
      "Epoch 22 Iter 7800 loss=394.8649 elbo -36.6450 sf -308.1799 selected 0.2000 kl 0.0603 ll -36.5847\n",
      "\n",
      "# epoch 22 iter 7843: dev loss 15.0556 elbo -38.1222 sf 23.0666 selected 0.3179 kl 0.0450 ll -38.0772 acc 0.2870\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Epoch    22: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Shuffling training data\n",
      "Epoch 23 Iter 7900 loss=391.4796 elbo -34.6629 sf -411.0714 selected 0.4000 kl 0.0352 ll -34.6277\n",
      "Epoch 23 Iter 8000 loss=391.6228 elbo -42.1379 sf -278.9145 selected 0.1600 kl 0.0406 ll -42.0973\n",
      "Epoch 23 Iter 8100 loss=394.0837 elbo -38.8557 sf -327.3164 selected 0.2400 kl 0.0306 ll -38.8251\n",
      "\n",
      "# epoch 23 iter 8184: dev loss 16.1673 elbo -38.2580 sf 22.0907 selected 0.2906 kl 0.0471 ll -38.2108 acc 0.2961\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Epoch 24 Iter 8200 loss=388.8144 elbo -37.2663 sf -341.6996 selected 0.2400 kl 0.0913 ll -37.1750\n",
      "Shuffling training data\n",
      "Epoch 24 Iter 8300 loss=395.9797 elbo -37.6296 sf -313.6859 selected 0.2000 kl 0.0150 ll -37.6146\n",
      "Epoch 24 Iter 8400 loss=396.3982 elbo -37.2990 sf -323.8447 selected 0.2400 kl 0.0479 ll -37.2512\n",
      "Epoch 24 Iter 8500 loss=399.2091 elbo -38.7499 sf -382.5517 selected 0.3600 kl 0.0477 ll -38.7023\n",
      "\n",
      "# epoch 24 iter 8525: dev loss 15.7380 elbo -38.3430 sf 22.6050 selected 0.3006 kl 0.0455 ll -38.2976 acc 0.2925\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 25 Iter 8600 loss=389.7988 elbo -41.8342 sf -446.1086 selected 0.4400 kl 0.0304 ll -41.8038\n",
      "Epoch 25 Iter 8700 loss=396.0265 elbo -38.3444 sf -328.1799 selected 0.2400 kl 0.0507 ll -38.2938\n",
      "Epoch 25 Iter 8800 loss=389.9925 elbo -38.3492 sf -363.2210 selected 0.3200 kl 0.0498 ll -38.2994\n",
      "\n",
      "# epoch 25 iter 8866: dev loss 16.4033 elbo -38.2451 sf 21.8418 selected 0.2807 kl 0.0549 ll -38.1902 acc 0.3079\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 26 Iter 8900 loss=391.0310 elbo -37.8118 sf -358.0812 selected 0.2800 kl 0.0427 ll -37.7690\n",
      "Epoch 26 Iter 9000 loss=394.8606 elbo -36.5110 sf -312.4062 selected 0.2400 kl 0.1020 ll -36.4090\n",
      "Epoch 26 Iter 9100 loss=382.6525 elbo -39.8450 sf -323.9276 selected 0.2400 kl 0.0858 ll -39.7592\n",
      "Epoch 26 Iter 9200 loss=389.7024 elbo -38.7517 sf -302.6433 selected 0.2000 kl 0.0256 ll -38.7261\n",
      "\n",
      "# epoch 26 iter 9207: dev loss 15.2433 elbo -38.1552 sf 22.9119 selected 0.3143 kl 0.0601 ll -38.0950 acc 0.2925\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 27 Iter 9300 loss=393.0658 elbo -38.9218 sf -325.7455 selected 0.2400 kl 0.0466 ll -38.8752\n",
      "Epoch 27 Iter 9400 loss=376.8285 elbo -38.0032 sf -368.1395 selected 0.3200 kl 0.0400 ll -37.9631\n",
      "Epoch 27 Iter 9500 loss=383.6447 elbo -37.8169 sf -348.5633 selected 0.3200 kl 0.0652 ll -37.7517\n",
      "\n",
      "# epoch 27 iter 9548: dev loss 15.7469 elbo -38.1850 sf 22.4381 selected 0.3006 kl 0.0624 ll -38.1227 acc 0.2843\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 28 Iter 9600 loss=384.4715 elbo -37.1931 sf -364.4625 selected 0.3200 kl 0.0692 ll -37.1239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Iter 9700 loss=387.7024 elbo -39.2907 sf -346.7596 selected 0.2800 kl 0.0928 ll -39.1979\n",
      "Epoch 28 Iter 9800 loss=391.2708 elbo -39.9536 sf -289.3063 selected 0.1600 kl 0.0518 ll -39.9018\n",
      "\n",
      "# epoch 28 iter 9889: dev loss 16.4107 elbo -38.2453 sf 21.8346 selected 0.2825 kl 0.0654 ll -38.1799 acc 0.2916\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Epoch 29 Iter 9900 loss=390.9712 elbo -38.8424 sf -399.0385 selected 0.3600 kl 0.0427 ll -38.7997\n",
      "Shuffling training data\n",
      "Epoch 29 Iter 10000 loss=404.3718 elbo -38.2164 sf -333.2902 selected 0.2400 kl 0.0767 ll -38.1398\n",
      "Epoch 29 Iter 10100 loss=412.9546 elbo -37.9969 sf -436.0792 selected 0.4000 kl 0.0517 ll -37.9452\n",
      "Epoch 29 Iter 10200 loss=407.1319 elbo -36.0486 sf -390.8026 selected 0.3200 kl 0.0359 ll -36.0127\n",
      "\n",
      "# epoch 29 iter 10230: dev loss 16.0184 elbo -38.1370 sf 22.1185 selected 0.2925 kl 0.0524 ll -38.0846 acc 0.2970\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 30 Iter 10300 loss=406.9031 elbo -36.5282 sf -347.9041 selected 0.2400 kl 0.0606 ll -36.4676\n",
      "Epoch 30 Iter 10400 loss=408.2156 elbo -39.8087 sf -319.7796 selected 0.2000 kl 0.0439 ll -39.7648\n",
      "Epoch 30 Iter 10500 loss=425.2133 elbo -37.2753 sf -396.5427 selected 0.3200 kl 0.0534 ll -37.2219\n",
      "\n",
      "# epoch 30 iter 10571: dev loss 16.4439 elbo -38.4818 sf 22.0379 selected 0.2779 kl 0.0534 ll -38.4284 acc 0.2698\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Epoch 31 Iter 10600 loss=414.2281 elbo -38.6012 sf -344.1785 selected 0.2400 kl 0.0462 ll -38.5551\n",
      "Shuffling training data\n",
      "Epoch 31 Iter 10700 loss=409.7390 elbo -39.4072 sf -279.9919 selected 0.1200 kl 0.0567 ll -39.3505\n",
      "Epoch 31 Iter 10800 loss=403.7887 elbo -38.6022 sf -422.7039 selected 0.3600 kl 0.0536 ll -38.5486\n",
      "Epoch 31 Iter 10900 loss=414.3828 elbo -37.8390 sf -442.7889 selected 0.4000 kl 0.0636 ll -37.7754\n",
      "\n",
      "# epoch 31 iter 10912: dev loss 16.2770 elbo -38.1310 sf 21.8541 selected 0.2834 kl 0.0533 ll -38.0777 acc 0.2943\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 32 Iter 11000 loss=387.8559 elbo -36.2909 sf -315.7462 selected 0.2000 kl 0.0824 ll -36.2085\n",
      "Epoch 32 Iter 11100 loss=397.6098 elbo -36.2765 sf -340.4425 selected 0.2400 kl 0.0878 ll -36.1887\n",
      "Epoch 32 Iter 11200 loss=397.0660 elbo -39.4167 sf -316.8251 selected 0.2000 kl 0.0540 ll -39.3627\n",
      "\n",
      "# epoch 32 iter 11253: dev loss 16.8681 elbo -38.3521 sf 21.4839 selected 0.2679 kl 0.0673 ll -38.2848 acc 0.2879\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 33 Iter 11300 loss=408.0523 elbo -39.6181 sf -315.2281 selected 0.2000 kl 0.0381 ll -39.5800\n",
      "Epoch 33 Iter 11400 loss=397.6990 elbo -39.1115 sf -381.8729 selected 0.3200 kl 0.0531 ll -39.0584\n",
      "Epoch 33 Iter 11500 loss=391.0523 elbo -38.4512 sf -326.9563 selected 0.2400 kl 0.0688 ll -38.3823\n",
      "\n",
      "# epoch 33 iter 11594: dev loss 17.3116 elbo -38.2689 sf 20.9573 selected 0.2598 kl 0.0674 ll -38.2015 acc 0.3052\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Epoch    33: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 34 Iter 11600 loss=399.7741 elbo -36.2024 sf -384.7180 selected 0.3200 kl 0.0417 ll -36.1607\n",
      "Shuffling training data\n",
      "Epoch 34 Iter 11700 loss=398.5219 elbo -36.8678 sf -328.2097 selected 0.2400 kl 0.0730 ll -36.7947\n",
      "Epoch 34 Iter 11800 loss=384.2304 elbo -37.4135 sf -323.6652 selected 0.2400 kl 0.0629 ll -37.3507\n",
      "Epoch 34 Iter 11900 loss=392.2059 elbo -36.7793 sf -465.7281 selected 0.5200 kl 0.0700 ll -36.7093\n",
      "\n",
      "# epoch 34 iter 11935: dev loss 16.7802 elbo -38.3207 sf 21.5405 selected 0.2661 kl 0.0628 ll -38.2580 acc 0.2952\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 35 Iter 12000 loss=389.7195 elbo -37.1452 sf -421.0379 selected 0.4400 kl 0.0637 ll -37.0815\n",
      "Epoch 35 Iter 12100 loss=369.2811 elbo -37.9139 sf -294.9917 selected 0.2000 kl 0.0653 ll -37.8486\n",
      "Epoch 35 Iter 12200 loss=373.1886 elbo -38.0446 sf -318.3228 selected 0.2400 kl 0.0664 ll -37.9782\n",
      "\n",
      "# epoch 35 iter 12276: dev loss 15.9889 elbo -38.2439 sf 22.2550 selected 0.2925 kl 0.0640 ll -38.1799 acc 0.3034\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Epoch 36 Iter 12300 loss=372.0511 elbo -37.8638 sf -302.2806 selected 0.2000 kl 0.0886 ll -37.7752\n",
      "Shuffling training data\n",
      "Epoch 36 Iter 12400 loss=384.9120 elbo -37.1955 sf -391.2165 selected 0.3600 kl 0.0534 ll -37.1421\n",
      "Epoch 36 Iter 12500 loss=382.7094 elbo -36.8212 sf -353.0390 selected 0.2800 kl 0.0641 ll -36.7570\n",
      "Epoch 36 Iter 12600 loss=386.6979 elbo -38.1899 sf -390.3755 selected 0.3600 kl 0.0640 ll -38.1258\n",
      "\n",
      "# epoch 36 iter 12617: dev loss 15.9320 elbo -38.3827 sf 22.4506 selected 0.2970 kl 0.0606 ll -38.3220 acc 0.2698\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 37 Iter 12700 loss=388.2007 elbo -36.0952 sf -334.9575 selected 0.2400 kl 0.0718 ll -36.0234\n",
      "Epoch 37 Iter 12800 loss=384.3080 elbo -36.3851 sf -375.8965 selected 0.3200 kl 0.0727 ll -36.3124\n",
      "Epoch 37 Iter 12900 loss=377.8131 elbo -40.3194 sf -265.9594 selected 0.1200 kl 0.0644 ll -40.2551\n",
      "\n",
      "# epoch 37 iter 12958: dev loss 16.4387 elbo -38.1761 sf 21.7374 selected 0.2807 kl 0.0643 ll -38.1117 acc 0.2970\n",
      " dev0 [gold=3,pred=1]: **it**\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 38 Iter 13000 loss=398.6068 elbo -39.6106 sf -347.0997 selected 0.2800 kl 0.0611 ll -39.5495\n",
      "Epoch 38 Iter 13100 loss=394.3286 elbo -38.2847 sf -376.3160 selected 0.3200 kl 0.0540 ll -38.2307\n",
      "Epoch 38 Iter 13200 loss=389.0721 elbo -38.6557 sf -430.0528 selected 0.4400 kl 0.0463 ll -38.6094\n",
      "\n",
      "# epoch 38 iter 13299: dev loss 16.2262 elbo -38.1555 sf 21.9293 selected 0.2852 kl 0.0666 ll -38.0888 acc 0.2925\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Epoch 39 Iter 13300 loss=379.6383 elbo -39.6526 sf -352.9229 selected 0.3200 kl 0.1109 ll -39.5417\n",
      "Shuffling training data\n",
      "Epoch 39 Iter 13400 loss=381.5906 elbo -38.2906 sf -369.9703 selected 0.3200 kl 0.0982 ll -38.1925\n",
      "Epoch 39 Iter 13500 loss=383.9105 elbo -40.9366 sf -315.9205 selected 0.2400 kl 0.0495 ll -40.8872\n",
      "Epoch 39 Iter 13600 loss=383.2126 elbo -37.1221 sf -250.8162 selected 0.1200 kl 0.0899 ll -37.0322\n",
      "\n",
      "# epoch 39 iter 13640: dev loss 16.2378 elbo -38.2409 sf 22.0031 selected 0.2843 kl 0.0664 ll -38.1746 acc 0.2879\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 40 Iter 13700 loss=384.7284 elbo -38.5466 sf -227.7118 selected 0.0800 kl 0.0525 ll -38.4941\n",
      "Epoch 40 Iter 13800 loss=373.7521 elbo -39.2111 sf -291.6556 selected 0.2000 kl 0.0721 ll -39.1390\n",
      "Epoch 40 Iter 13900 loss=376.1715 elbo -36.2221 sf -368.1546 selected 0.3600 kl 0.0788 ll -36.1433\n",
      "\n",
      "# epoch 40 iter 13981: dev loss 16.4658 elbo -38.2989 sf 21.8331 selected 0.2788 kl 0.0682 ll -38.2307 acc 0.2916\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Epoch 41 Iter 14000 loss=379.3096 elbo -37.6385 sf -368.7838 selected 0.3200 kl 0.0933 ll -37.5451\n",
      "Shuffling training data\n",
      "Epoch 41 Iter 14100 loss=376.8443 elbo -41.5015 sf -359.6233 selected 0.3200 kl 0.0688 ll -41.4327\n",
      "Epoch 41 Iter 14200 loss=377.5877 elbo -38.5687 sf -326.4899 selected 0.2800 kl 0.0859 ll -38.4828\n",
      "Epoch 41 Iter 14300 loss=379.8740 elbo -37.8348 sf -370.2873 selected 0.3200 kl 0.1210 ll -37.7138\n",
      "\n",
      "# epoch 41 iter 14322: dev loss 16.5569 elbo -38.1652 sf 21.6083 selected 0.2779 kl 0.0724 ll -38.0928 acc 0.2752\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 42 Iter 14400 loss=382.6042 elbo -41.4544 sf -345.9789 selected 0.2800 kl 0.1313 ll -41.3231\n",
      "Epoch 42 Iter 14500 loss=386.0366 elbo -37.6002 sf -296.7667 selected 0.2000 kl 0.0676 ll -37.5325\n",
      "Epoch 42 Iter 14600 loss=376.1815 elbo -39.3598 sf -372.7417 selected 0.3200 kl 0.0547 ll -39.3051\n",
      "\n",
      "# epoch 42 iter 14663: dev loss 16.6159 elbo -38.3104 sf 21.6945 selected 0.2761 kl 0.0738 ll -38.2367 acc 0.2934\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Epoch 43 Iter 14700 loss=389.0206 elbo -36.7090 sf -354.1073 selected 0.2800 kl 0.0780 ll -36.6310\n",
      "Shuffling training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Iter 14800 loss=388.6488 elbo -38.7677 sf -341.6519 selected 0.2800 kl 0.0658 ll -38.7019\n",
      "Epoch 43 Iter 14900 loss=400.2766 elbo -35.6973 sf -264.5222 selected 0.1200 kl 0.0559 ll -35.6414\n",
      "Epoch 43 Iter 15000 loss=390.0959 elbo -38.9741 sf -398.3192 selected 0.3200 kl 0.0974 ll -38.8767\n",
      "\n",
      "# epoch 43 iter 15004: dev loss 16.8339 elbo -38.2826 sf 21.4487 selected 0.2679 kl 0.0723 ll -38.2103 acc 0.2943\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 44 Iter 15100 loss=399.0823 elbo -38.0964 sf -450.2261 selected 0.4400 kl 0.0616 ll -38.0348\n",
      "Epoch 44 Iter 15200 loss=386.0313 elbo -36.9670 sf -433.8979 selected 0.4000 kl 0.0923 ll -36.8747\n",
      "Epoch 44 Iter 15300 loss=390.0973 elbo -38.0727 sf -384.6142 selected 0.3200 kl 0.0868 ll -37.9860\n",
      "\n",
      "# epoch 44 iter 15345: dev loss 16.7785 elbo -38.1585 sf 21.3800 selected 0.2716 kl 0.0762 ll -38.0823 acc 0.2970\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Epoch    44: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Shuffling training data\n",
      "Epoch 45 Iter 15400 loss=391.2463 elbo -36.1671 sf -393.5882 selected 0.3600 kl 0.0924 ll -36.0747\n",
      "Epoch 45 Iter 15500 loss=378.6352 elbo -39.1581 sf -373.2943 selected 0.3200 kl 0.0896 ll -39.0685\n",
      "Epoch 45 Iter 15600 loss=398.9823 elbo -38.9747 sf -338.8594 selected 0.2800 kl 0.0720 ll -38.9026\n",
      "\n",
      "# epoch 45 iter 15686: dev loss 16.7682 elbo -38.3105 sf 21.5423 selected 0.2761 kl 0.0774 ll -38.2331 acc 0.2852\n",
      " dev0 [gold=3,pred=3]: **it**\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: **and**\n",
      "\n",
      "Epoch 46 Iter 15700 loss=399.9869 elbo -38.5761 sf -360.3518 selected 0.2800 kl 0.0563 ll -38.5198\n",
      "Shuffling training data\n",
      "Epoch 46 Iter 15800 loss=383.2891 elbo -36.7681 sf -240.5709 selected 0.0800 kl 0.1083 ll -36.6598\n",
      "Epoch 46 Iter 15900 loss=383.6559 elbo -34.5120 sf -304.3206 selected 0.2000 kl 0.0978 ll -34.4142\n",
      "Epoch 46 Iter 16000 loss=378.1781 elbo -39.3748 sf -266.1605 selected 0.1600 kl 0.0978 ll -39.2770\n",
      "\n",
      "# epoch 46 iter 16027: dev loss 16.7733 elbo -38.1371 sf 21.3638 selected 0.2716 kl 0.0792 ll -38.0580 acc 0.2843\n",
      " dev0 [gold=3,pred=1]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 47 Iter 16100 loss=376.0208 elbo -38.5228 sf -309.2852 selected 0.2000 kl 0.0860 ll -38.4368\n",
      "Epoch 47 Iter 16200 loss=372.4063 elbo -39.5360 sf -459.9535 selected 0.5200 kl 0.0579 ll -39.4781\n",
      "Epoch 47 Iter 16300 loss=373.9063 elbo -36.6916 sf -319.7656 selected 0.2400 kl 0.0943 ll -36.5973\n",
      "\n",
      "# epoch 47 iter 16368: dev loss 14.7159 elbo -38.0709 sf 23.3549 selected 0.3233 kl 0.0770 ll -37.9939 acc 0.2925\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n",
      "Epoch 48 Iter 16400 loss=368.0017 elbo -37.6677 sf -300.5112 selected 0.2000 kl 0.0755 ll -37.5921\n",
      "Shuffling training data\n",
      "Epoch 48 Iter 16500 loss=363.2568 elbo -36.3454 sf -357.9590 selected 0.3200 kl 0.0706 ll -36.2748\n",
      "Epoch 48 Iter 16600 loss=369.7062 elbo -37.8339 sf -316.2186 selected 0.2400 kl 0.0971 ll -37.7368\n",
      "Epoch 48 Iter 16700 loss=356.7758 elbo -38.1787 sf -201.4401 selected 0.0400 kl 0.0927 ll -38.0859\n",
      "\n",
      "# epoch 48 iter 16709: dev loss 15.6821 elbo -38.1222 sf 22.4401 selected 0.3006 kl 0.0816 ll -38.0406 acc 0.2888\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 49 Iter 16800 loss=365.6792 elbo -40.6951 sf -272.9016 selected 0.1600 kl 0.1028 ll -40.5924\n",
      "Epoch 49 Iter 16900 loss=363.1223 elbo -38.1615 sf -315.2480 selected 0.2400 kl 0.1164 ll -38.0451\n",
      "Epoch 49 Iter 17000 loss=369.2519 elbo -41.9670 sf -340.0775 selected 0.2800 kl 0.0901 ll -41.8768\n",
      "\n",
      "# epoch 49 iter 17050: dev loss 16.6059 elbo -38.2143 sf 21.6084 selected 0.2779 kl 0.0869 ll -38.1274 acc 0.2888\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: **no**\n",
      " dev2 [gold=3,pred=3]: and\n",
      "\n",
      "Epoch 50 Iter 17100 loss=378.5217 elbo -28.1871 sf -307.6066 selected 0.3684 kl 0.0534 ll -28.1336\n",
      "Shuffling training data\n",
      "Epoch 50 Iter 17200 loss=387.6891 elbo -39.9304 sf -286.2912 selected 0.2000 kl 0.1290 ll -39.8014\n",
      "Epoch 50 Iter 17300 loss=384.7193 elbo -40.1126 sf -340.0527 selected 0.2800 kl 0.0948 ll -40.0178\n",
      "\n",
      "# epoch 50 iter 17391: dev loss 16.4710 elbo -38.3352 sf 21.8642 selected 0.2816 kl 0.0855 ll -38.2497 acc 0.2988\n",
      " dev0 [gold=3,pred=3]: it\n",
      " dev1 [gold=2,pred=3]: no\n",
      " dev2 [gold=3,pred=1]: and\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w_Ko657vRGo"
   },
   "source": [
    "# Variance reduction\n",
    "\n",
    "**This is an extra**\n",
    "\n",
    "We can use a *control variate* to reduce the variance of our gradient estimates.\n",
    "\n",
    "Let's recap the idea in general terms. We are looking to solve some expectation\n",
    "\\begin{align}\n",
    "\\mu_f = \\mathbb E[f(Z)]\n",
    "\\end{align}\n",
    "but unfortunatelly, realising the full sum (or integral for continuous variables) is intractable. Thus we employ MC estimation\n",
    "\\begin{align}\n",
    "\\hat \\mu_f &\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S f(z_s) & \\text{where }z_s \\sim Q(z|x)\n",
    "\\end{align}\n",
    "Note that the variance of this estimate is\n",
    "\\begin{align}\n",
    "\\text{Var}(\\hat \\mu_f) &=  \\frac{1}{S}\\text{Var}(f(Z)) \\\\\n",
    "&= \\frac{1}{S} \\mathbb E[( f(Z) - \\mathbb E[f(Z)])^2]\n",
    "\\end{align}\n",
    "Note that this variance is such that it goes down as we sample more, in a rate $\\mathcal O(S^{-1})$.\n",
    "See that if we sample $10$ times more, we will only obtain an decrease in variance in the order of $10^{-1}$. This means that sampling more is generally not the most convenient way to decrease variance.\n",
    "\n",
    "*Digression* we can estimate the variance itself via MC, an unbiased estimate looks like\n",
    "\\begin{align}\n",
    "\\hat \\sigma^2_f = \\frac{1}{S(S-1)} \\sum_{s=1}^S (f(z_s) - \\hat \\mu_f)^2\n",
    "\\end{align}\n",
    "but not that this estimate is even hard to improve since it decreases with $\\mathcal O(S^{-2})$.\n",
    "\n",
    "Back to out main problem: let's try and improve the variance of our estimator to $\\mu_f$.\n",
    "\n",
    "It's a fact, and it can be shown trivially, that\n",
    "\\begin{align}\n",
    "\\mu_f &=  \\mathbb E[f(Z) - \\psi(Z)] + \\underbrace{\\mathbb E[\\psi(Z)]}_{\\mu_\\psi} \\\\\n",
    " &\\overset{\\text{MC}}{\\approx} \\underbrace{\\left(\\frac{1}{S} \\sum_{s=1}^S f(z_s) - \\psi(z_s) \\right) + \\mu_\\psi}_{\\hat c}\n",
    "\\end{align}\n",
    "where we assume the existence of some function $\\psi(z)$ for which the expected value $\\mu_\\psi$ is known and we estimate the expected difference $\\mathbb E[f(Z) - \\psi(Z)]$ via MC. We used this axuxiliary function, also known as a *control variate*, to derive a new estimator, which we will denote by $\\hat c$.\n",
    "\n",
    "The variance of this new estimator is show below:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}( \\hat c ) &= \\text{Var}(\\hat \\mu_{f-\\psi}) + 2\\underbrace{\\text{Cov}(\\hat \\mu_{f-\\psi}, \\mu_\\psi)}_{\\mathbb E[\\hat \\mu_{f-\\psi}  \\mu_\\psi] - \\mathbb E[\\hat \\mu_{f-\\psi}] \\mathbb E[\\mu_\\psi]} + \\underbrace{\\text{Var}(\\mu_\\psi)}_{\\color{blue}{0} } \\\\\n",
    "&= \\frac{1}{S}\\text{Var}(f- \\psi)  + 2 \\underbrace{\\left( \\mu_\\psi \\mu_{f-\\psi} - \\mu_{f-\\psi} \\mu_\\psi \\right)}_{\\color{blue}{0}} \n",
    "\\end{align}\n",
    "where the variance of $\\mu_\\psi$ is 0 because we know it in closed form (no need for MC estimation), and the covariance is $0$ as shown in the second row.\n",
    "\n",
    "That is, the variance of $\\hat c$ is essentially the variance of estimating $\\mathbb E[f(Z) - \\psi(Z)]$, which in turn depends on the variance \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(f-\\psi) &= \\text{Var}(f) - 2\\text{Cov}(f, \\psi) + \\text{Var}(\\psi)\n",
    "\\end{align}\n",
    "where we can see that if $\\text{Cov}(f, \\psi) > \\frac{\\text{Var}(\\psi)}{2}$ we achieve variance reduction as then $\\text{Var}(f-\\psi)$ would be smaller than $\\text{Var(f)}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovKcRnqH_PGp"
   },
   "source": [
    "\n",
    "## Baselines\n",
    "\n",
    "Baslines are control variates of a very simple form:\n",
    "\\begin{align}\n",
    "\\mathbb E[f(Z)] = \\mathbb E[f(Z) - C] + \\mathbb E[C]\n",
    "\\end{align}\n",
    "where $C$ is a constant with respect to $z$.\n",
    "\n",
    "In the context of the score function estimator, a baseline looks like a quantity $C(x; \\omega)$, this may be\n",
    "* just a constant;\n",
    "* or a function of the input (but not of the latent variable), which could be itself implemented as a neural network;\n",
    "* a combination of the two.\n",
    " \n",
    "\n",
    "Let's focus on the first term of the ELBO (so I'm omitting the KL term here). The gradient with respect to parameters of the inference model becomes:\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\\\\\n",
    "&=\\mathbb E_{Q(z|x, \\lambda)}\\left[\\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) - \\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] + \\underbrace{\\mathbb E_{Q(z|x, \\lambda)}\\left[\\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] }_{=0} \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\color{blue}{\\left(\\log P(x|z, \\theta) - C(x; \\omega) \\right)}\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right] \\\\\n",
    "&\n",
    "\\end{align}\n",
    "We can show that the last term is $0$\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]  \\\\&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]\\\\\n",
    "&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\right] \\\\\n",
    "&= C(x; \\omega) \\sum_z Q(z|x, \\lambda) \\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\\\\n",
    "&= C(x; \\omega) \\sum_z\\nabla_\\lambda Q(z|x, \\lambda)  \\\\\n",
    "&= C(x; \\omega) \\nabla_\\lambda \\underbrace{\\sum_z Q(z|x, \\lambda)  }_{=1}\\\\\n",
    "&=0\n",
    "\\end{align}\n",
    "\n",
    "Examples of useful baselines:\n",
    "\n",
    "* a running average of the learning signal: at some iteration $t$ we can use a running average of $\\log P(x|z, \\theta)$ using parameter estimates $\\theta$ from iterations $i < t$, this is a baseline that likely leads to high correlation between control variate and learning signal and can lead to variance reduction;\n",
    "* another technique is to have an MLP with parameters $\\omega$ predict a scalar and train this MLP to approximate the learning signal $\\log P(x|z, \\theta)$ via regression:\n",
    "\\begin{align}\n",
    "\\arg\\max_\\omega \\left( C(x; \\omega) - \\log P(x|z, \\theta) \\right)^2\n",
    "\\end{align}\n",
    "its left as an extra to implement these ideas.\n",
    "\n",
    "One more note: we can also use something called a *multiplicative baseline* in the literature of reinforcement learning, whereby we incorporate a running estimate of the standard deviation of the learning signal computed based on the values attained on previous iterations:\n",
    "\\begin{align}\n",
    "\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\frac{1}{\\hat\\sigma_{\\text{past}}}\\left(\\log P(x|z, \\theta) - \\hat \\mu_{\\text{past}}\\right)\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\n",
    "\\end{align}\n",
    "this form of contorl variate aim at promoting the learning signal (or reward in reinforcement learning literature) to be distributed by $\\mathcal N(0, 1)$. Note that multiplying the reward by a constant does not bias the estimator, and in this case, may lead to variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVsWgmlIWvZq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2VntYV3WvZt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTxG1AvPWvZv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "SST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
